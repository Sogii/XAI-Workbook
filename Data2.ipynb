{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def check_for_nans(df, file_name):\n",
    "    nan_rows = df[df.isna().any(axis=1)]\n",
    "    if not nan_rows.empty:\n",
    "        print(f\"NaN values found in file: {file_name}\")\n",
    "        for index, row in nan_rows.iterrows():\n",
    "            print(f\"Line {index + 1}: {row[row.isna()].index.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_all: (1502, 374)\n",
      "Shape of y_all: (1502,)\n",
      "Sample feature entry 1 (with headers):\n",
      "   RelativeTime_t-10  CollectableCoin1Distance_t-10  \\\n",
      "0                0.0                           -1.0   \n",
      "\n",
      "   CollectableCoin2Distance_t-10  CollectableCoin3Distance_t-10  \\\n",
      "0                           -1.0                           -1.0   \n",
      "\n",
      "   CollectableCoin4Distance_t-10  CollectableCoin5Distance_t-10  \\\n",
      "0                           -1.0                           -1.0   \n",
      "\n",
      "   TimeStepCoinsCollected_t-10  TimeStepCoinNearMiss_t-10  \\\n",
      "0                          0.0                        0.0   \n",
      "\n",
      "   Asteroid1Distance_t-10  Asteroid2Distance_t-10  ...  \\\n",
      "0                    -1.0                    -1.0  ...   \n",
      "\n",
      "   VeryRecentScoreDifference_t+1  RecentScoreDifference_t+1  \\\n",
      "0                          838.5                      843.6   \n",
      "\n",
      "   LongTermScoreDifference_t+1  VeryRecentMultiplierDifference_t+1  \\\n",
      "0                        843.6                                 1.2   \n",
      "\n",
      "   RecentMultiplierDifference_t+1  LongTermMultiplierDifference_t+1  \\\n",
      "0                             1.2                               1.2   \n",
      "\n",
      "   TotalAsteroidNearMisses_t+1  TotalAsteroidHits_t+1  TotalCoinCollected_t+1  \\\n",
      "0                          0.0                    0.0                     2.0   \n",
      "\n",
      "   TotalCoinNearmisses_t+1  \n",
      "0                      0.0  \n",
      "\n",
      "[1 rows x 374 columns]\n",
      "Sample feature entry 2 (with headers):\n",
      "   RelativeTime_t-10  CollectableCoin1Distance_t-10  \\\n",
      "0                0.5                           -1.0   \n",
      "\n",
      "   CollectableCoin2Distance_t-10  CollectableCoin3Distance_t-10  \\\n",
      "0                           -1.0                           -1.0   \n",
      "\n",
      "   CollectableCoin4Distance_t-10  CollectableCoin5Distance_t-10  \\\n",
      "0                           -1.0                           -1.0   \n",
      "\n",
      "   TimeStepCoinsCollected_t-10  TimeStepCoinNearMiss_t-10  \\\n",
      "0                          0.0                        0.0   \n",
      "\n",
      "   Asteroid1Distance_t-10  Asteroid2Distance_t-10  ...  \\\n",
      "0                    10.9                    -1.0  ...   \n",
      "\n",
      "   VeryRecentScoreDifference_t+1  RecentScoreDifference_t+1  \\\n",
      "0                          844.3                      854.8   \n",
      "\n",
      "   LongTermScoreDifference_t+1  VeryRecentMultiplierDifference_t+1  \\\n",
      "0                        854.8                                 1.2   \n",
      "\n",
      "   RecentMultiplierDifference_t+1  LongTermMultiplierDifference_t+1  \\\n",
      "0                             1.3                               1.3   \n",
      "\n",
      "   TotalAsteroidNearMisses_t+1  TotalAsteroidHits_t+1  TotalCoinCollected_t+1  \\\n",
      "0                          0.0                    0.0                     2.0   \n",
      "\n",
      "   TotalCoinNearmisses_t+1  \n",
      "0                      0.0  \n",
      "\n",
      "[1 rows x 374 columns]\n",
      "Sample label entry 1: 2.0\n",
      "Sample label entry 2: 2.0\n",
      "Shape of X_train: (1201, 374)\n",
      "Shape of X_test: (301, 374)\n",
      "Shape of y_train: (1201,)\n",
      "Shape of y_test: (301,)\n",
      "Cross-Validation R^2 Scores: [0.40013839 0.38385088 0.13549457 0.21014928 0.33180397]\n",
      "Mean R^2 Score: 0.29228741569220046\n",
      "Standard Deviation of R^2 Scores: 0.10286683493807966\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# tsv_files = glob.glob('data/*.tsv')\n",
    "tsv_files = glob.glob(\"data/newdata/*.tsv\")\n",
    "\n",
    "# Opportunity to filter the files (based on folder for example)\n",
    "filtered_files = tsv_files\n",
    "\n",
    "# Window sizes\n",
    "n_past = 10\n",
    "m_future = 1\n",
    "\n",
    "# List to store all sliding window features and labels\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through each TSV file\n",
    "for file in tsv_files:\n",
    "    df = pd.read_csv(file, delimiter=\"\\t\")\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"SequenceID\",\n",
    "            \"TimeStamp\",\n",
    "            \"First30SecondsCoinsCollected\",\n",
    "            \"First30SecondsAsteroidHits\",\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    check_for_nans(df, file)\n",
    "    # Create sliding window\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through the data to create windows\n",
    "    for i in range(n_past, len(df) - m_future):\n",
    "        window_features = []\n",
    "\n",
    "        # Add past entries (t-n to t-1)\n",
    "        for j in range(n_past):\n",
    "            window_features.extend(df.iloc[i - n_past + j].drop(\"Score\").values)\n",
    "        # Add future entries (t+1 to t+m)\n",
    "        for j in range(1, m_future + 1):\n",
    "            window_features.extend(df.iloc[i + j].drop(\"Score\").values)\n",
    "\n",
    "        # Append the current feature vector and label\n",
    "        features.append(window_features)\n",
    "        labels.append(df.iloc[i][\"Score\"])\n",
    "\n",
    "    all_features.append(np.array(features))\n",
    "    all_labels.append(np.array(labels))\n",
    "\n",
    "# Concatenate all features and labels\n",
    "X_all = np.concatenate(all_features)\n",
    "y_all = np.concatenate(all_labels)\n",
    "\n",
    "# Define the column names based on the original DataFrame\n",
    "original_columns = df.drop(columns=[\"Score\"]).columns\n",
    "num_features = X_all.shape[1]\n",
    "column_names = [f'{col}_t-{n_past-j}' for j in range(n_past) for col in original_columns] + \\\n",
    "               [f'{col}_t+{j}' for j in range(1, m_future + 1) for col in original_columns]\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"Shape of X_all: {X_all.shape}\")\n",
    "print(f\"Shape of y_all: {y_all.shape}\")\n",
    "\n",
    "# Print sample entries with adjusted headers\n",
    "print(\"Sample feature entry 1 (with headers):\")\n",
    "print(pd.DataFrame([X_all[0]], columns=column_names))\n",
    "print(\"Sample feature entry 2 (with headers):\")\n",
    "print(pd.DataFrame([X_all[1]], columns=column_names))\n",
    "print(\"Sample label entry 1:\", y_all[0])\n",
    "print(\"Sample label entry 2:\", y_all[1])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print shapes of the training and testing sets\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "\n",
    "# Disable scientific notation for better readability\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(model, X_all, y_all, cv=kf, scoring='r2')\n",
    "\n",
    "# Calculate mean and standard deviation of the cross-validation scores\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "\n",
    "print(f\"Cross-Validation R^2 Scores: {cv_scores}\")\n",
    "print(f\"Mean R^2 Score: {mean_cv_score}\")\n",
    "print(f\"Standard Deviation of R^2 Scores: {std_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Tests\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel R^2 score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, mean_absolute_error, r2_score\n",
      "File \u001b[1;32mc:\\Users\\svanl\\Documents\\repositories\\XAI Workbook\\.venv\\Lib\\site-packages\\sklearn\\base.py:848\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[1;32m--> 848\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\svanl\\Documents\\repositories\\XAI Workbook\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:306\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    293\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\svanl\\Documents\\repositories\\XAI Workbook\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:283\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m--> 283\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    286\u001b[0m     coef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\n",
      "File \u001b[1;32mc:\\Users\\svanl\\Documents\\repositories\\XAI Workbook\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "#Tests\n",
    "# Evaluate the model\n",
    "model.fit(X_train, y_train)  # Fit the model\n",
    "\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"Model R^2 score: {score}\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Generate learning curve data\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X_all, y_all, cv=5, scoring='r2', n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color='r')\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color='g')\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances = model.coef_\n",
    "\n",
    "# Extract base feature names\n",
    "base_feature_names = [col.split('_')[0] for col in column_names]\n",
    "\n",
    "# Aggregate feature importances by base feature names\n",
    "aggregated_importances = {}\n",
    "for base_feature in set(base_feature_names):\n",
    "    aggregated_importances[base_feature] = np.sum([importance for feature, importance in zip(base_feature_names, feature_importances) if feature == base_feature])\n",
    "\n",
    "# Convert to DataFrame for easier plotting\n",
    "aggregated_importances_df = pd.DataFrame(list(aggregated_importances.items()), columns=['Feature', 'Importance'])\n",
    "aggregated_importances_df = aggregated_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot aggregated feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(aggregated_importances_df['Feature'], aggregated_importances_df['Importance'])\n",
    "plt.xlabel('Aggregated Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Aggregated Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature at the top\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
